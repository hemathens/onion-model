{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-header",
   "metadata": {},
   "source": [
    "# Onion Shelf Life Prediction Model Training\n",
    "## Computer Vision-Based Quality Assessment System\n",
    "\n",
    "**Project Overview:**\n",
    "This notebook documents the complete training pipeline for an onion shelf life prediction model using computer vision and deep learning. The model classifies onions into 4 quality classes based on visual features extracted from images.\n",
    "\n",
    "**Model Classes:**\n",
    "- Class 0: Severe deterioration (0 days shelf life)\n",
    "- Class 1: Poor quality (5-10 days shelf life)\n",
    "- Class 2: Fair quality (15-19 days shelf life)\n",
    "- Class 3: Excellent quality (29-37 days shelf life)\n",
    "\n",
    "**Author:** Onion Quality Assessment Team  \n",
    "**Date:** February 2026  \n",
    "**Framework:** TensorFlow.js / Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-extraction-header",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction Functions\n",
    "\n",
    "These functions extract visual features from onion images using computer vision techniques. Features include:\n",
    "- Physical dimensions (diameter, size classification)\n",
    "- Black spots count (dark pixel detection)\n",
    "- Surface texture score (local variance analysis)\n",
    "- Skin condition score (brightness/saturation analysis)\n",
    "- Damage indicators (bruises, cuts, lesions)\n",
    "- Sprouting detection (green pixel ratio)\n",
    "- Color analysis (brightness, saturation, uniformity)\n",
    "- Firmness indicators\n",
    "- Root condition assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnionFeatureExtractor:\n",
    "    \"\"\"Extract visual features from onion images for quality assessment\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.features = {}\n",
    "    \n",
    "    def is_onion_pixel(self, r, g, b):\n",
    "        \"\"\"Check if pixel color matches onion characteristics\"\"\"\n",
    "        brightness = (r + g + b) / 3\n",
    "        \n",
    "        # Brown/Golden/Yellow onion\n",
    "        if 80 <= r <= 230 and 50 <= g <= 200 and 20 <= b <= 130 and r > b + 20:\n",
    "            return True\n",
    "        # White onion\n",
    "        if r >= 170 and g >= 170 and b >= 170:\n",
    "            return True\n",
    "        # Purple/Red onion\n",
    "        if 80 <= r <= 180 and 70 <= b <= 170 and r > g - 10 and b > g - 30:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def estimate_dimensions(self, image):\n",
    "        \"\"\"Estimate onion dimensions from image\"\"\"\n",
    "        height, width = image.shape[:2]\n",
    "        min_x, max_x = width, 0\n",
    "        min_y, max_y = height, 0\n",
    "        onion_pixels = 0\n",
    "        \n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                b, g, r = image[y, x]\n",
    "                \n",
    "                if self.is_onion_pixel(r, g, b):\n",
    "                    onion_pixels += 1\n",
    "                    min_x = min(min_x, x)\n",
    "                    max_x = max(max_x, x)\n",
    "                    min_y = min(min_y, y)\n",
    "                    max_y = max(max_y, y)\n",
    "        \n",
    "        pixel_width = max_x - min_x\n",
    "        pixel_height = max_y - min_y\n",
    "        \n",
    "        # Estimate real dimensions (assuming average onion is ~75mm)\n",
    "        scale_factor = 75 / max(pixel_width, pixel_height) if max(pixel_width, pixel_height) > 0 else 1\n",
    "        \n",
    "        diameter_mm = round(max(pixel_width, pixel_height) * scale_factor, 1)\n",
    "        \n",
    "        # Size classification\n",
    "        if diameter_mm < 50:\n",
    "            size_class = 'Small'\n",
    "        elif diameter_mm < 75:\n",
    "            size_class = 'Medium'\n",
    "        elif diameter_mm < 100:\n",
    "            size_class = 'Large'\n",
    "        else:\n",
    "            size_class = 'Extra Large'\n",
    "        \n",
    "        return {\n",
    "            'diameter_mm': diameter_mm,\n",
    "            'size_class': size_class,\n",
    "            'length_mm': round(pixel_height * scale_factor, 1),\n",
    "            'width_mm': round(pixel_width * scale_factor, 1)\n",
    "        }\n",
    "    \n",
    "    def count_black_spots(self, image):\n",
    "        \"\"\"Count black spots on onion surface\"\"\"\n",
    "        height, width = image.shape[:2]\n",
    "        dark_spot_pixels = 0\n",
    "        onion_pixels = 0\n",
    "        \n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                b, g, r = image[y, x]\n",
    "                \n",
    "                if self.is_onion_pixel(r, g, b):\n",
    "                    onion_pixels += 1\n",
    "                    brightness = (r + g + b) / 3\n",
    "                    \n",
    "                    # Dark spots: significantly darker than normal onion\n",
    "                    if 20 < brightness < 80:\n",
    "                        dark_spot_pixels += 1\n",
    "        \n",
    "        if onion_pixels == 0:\n",
    "            return 0\n",
    "        \n",
    "        dark_ratio = dark_spot_pixels / onion_pixels\n",
    "        \n",
    "        # Map ratio to spot count (0-21 range)\n",
    "        if dark_ratio < 0.02:\n",
    "            spot_count = int(dark_ratio * 100)\n",
    "        elif dark_ratio < 0.08:\n",
    "            spot_count = 2 + int((dark_ratio - 0.02) * 100)\n",
    "        else:\n",
    "            spot_count = 8 + int((dark_ratio - 0.08) * 150)\n",
    "        \n",
    "        return min(21, max(0, spot_count))\n",
    "    \n",
    "    def analyze_surface_texture(self, image):\n",
    "        \"\"\"Analyze surface texture (1=smooth to 4=very soft)\"\"\"\n",
    "        height, width = image.shape[:2]\n",
    "        total_variance = 0\n",
    "        samples = 0\n",
    "        \n",
    "        # Calculate local variance as texture indicator\n",
    "        for y in range(10, height - 10, 10):\n",
    "            for x in range(10, width - 10, 10):\n",
    "                patch = image[y-5:y+5, x-5:x+5]\n",
    "                variance = np.var(patch)\n",
    "                total_variance += variance\n",
    "                samples += 1\n",
    "        \n",
    "        avg_variance = total_variance / samples if samples > 0 else 0\n",
    "        \n",
    "        # Map variance to texture score\n",
    "        if avg_variance < 100:\n",
    "            return 1  # Smooth\n",
    "        elif avg_variance < 300:\n",
    "            return 2  # Slightly wrinkled\n",
    "        elif avg_variance < 600:\n",
    "            return 3  # Wrinkled\n",
    "        else:\n",
    "            return 4  # Very soft/deteriorated\n",
    "    \n",
    "    def analyze_skin_condition(self, image):\n",
    "        \"\"\"Analyze skin condition (1=excellent to 5=poor)\"\"\"\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Analyze saturation and value\n",
    "        avg_saturation = np.mean(hsv[:, :, 1])\n",
    "        avg_value = np.mean(hsv[:, :, 2])\n",
    "        \n",
    "        # Higher saturation and value = better condition\n",
    "        condition_score = (avg_saturation + avg_value) / 2\n",
    "        \n",
    "        if condition_score > 180:\n",
    "            return 1  # Excellent\n",
    "        elif condition_score > 140:\n",
    "            return 2  # Good\n",
    "        elif condition_score > 100:\n",
    "            return 3  # Fair\n",
    "        elif condition_score > 60:\n",
    "            return 4  # Poor\n",
    "        else:\n",
    "            return 5  # Very poor\n",
    "    \n",
    "    def extract_all_features(self, image_path):\n",
    "        \"\"\"Extract all features from an onion image\"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        dimensions = self.estimate_dimensions(image)\n",
    "        black_spots = self.count_black_spots(image)\n",
    "        texture = self.analyze_surface_texture(image)\n",
    "        skin_condition = self.analyze_skin_condition(image)\n",
    "        \n",
    "        return {\n",
    "            **dimensions,\n",
    "            'black_spots_count': black_spots,\n",
    "            'surface_texture_score': texture,\n",
    "            'skin_condition_score': skin_condition\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-architecture-header",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "Build a neural network for shelf life classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shelf_life_model(input_dim):\n",
    "    \"\"\"Create neural network model for shelf life prediction\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(4, activation='softmax')  # 4 quality classes\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## 4. Training Pipeline\n",
    "\n",
    "Load data, train model, and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('onion_shelf_life_dataset.csv')\n",
    "\n",
    "# Prepare features and labels\n",
    "feature_columns = [\n",
    "    'diameter_mm', 'black_spots_count', 'surface_texture_score',\n",
    "    'skin_condition_score', 'has_bruises', 'has_cuts', 'has_lesions'\n",
    "]\n",
    "\n",
    "X = df[feature_columns].values\n",
    "\n",
    "# Convert shelf life to classes\n",
    "def shelf_life_to_class(days):\n",
    "    if days < 5:\n",
    "        return 0  # Severe\n",
    "    elif days < 15:\n",
    "        return 1  # Poor\n",
    "    elif days < 25:\n",
    "        return 2  # Fair\n",
    "    else:\n",
    "        return 3  # Excellent\n",
    "\n",
    "y = df['estimated_shelf_life_days'].apply(shelf_life_to_class).values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train model\n",
    "model = create_shelf_life_model(X_train.shape[1])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Severe', 'Poor', 'Fair', 'Excellent']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-model-header",
   "metadata": {},
   "source": [
    "## 5. Save Model for TensorFlow.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in TensorFlow.js format\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "tfjs.converters.save_keras_model(model, 'my_model')\n",
    "print(\"Model saved for TensorFlow.js\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
