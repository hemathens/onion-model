{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3f4423",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-26T17:49:15.341252Z",
     "iopub.status.busy": "2026-01-26T17:49:15.339850Z",
     "iopub.status.idle": "2026-01-26T17:49:17.801355Z",
     "shell.execute_reply": "2026-01-26T17:49:17.800455Z"
    },
    "papermill": {
     "duration": 2.467723,
     "end_time": "2026-01-26T17:49:17.803408",
     "exception": false,
     "start_time": "2026-01-26T17:49:15.335685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416f81a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T17:49:17.810337Z",
     "iopub.status.busy": "2026-01-26T17:49:17.809709Z",
     "iopub.status.idle": "2026-01-26T17:49:17.952865Z",
     "shell.execute_reply": "2026-01-26T17:49:17.951009Z"
    },
    "papermill": {
     "duration": 0.149512,
     "end_time": "2026-01-26T17:49:17.955254",
     "exception": false,
     "start_time": "2026-01-26T17:49:17.805742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 200 onion data points for image-based shelf life prediction...\n",
      "Dataset created with 200 samples\n",
      "Shape: (200, 15)\n",
      "\n",
      "First few rows:\n",
      "  sample_id  length_mm  width_mm  height_mm  diameter_mm size_class  \\\n",
      "0   ONI_001       73.1      88.9       96.7         96.7      Large   \n",
      "1   ONI_002       71.1      78.5       76.5         78.5      Large   \n",
      "2   ONI_003       61.0      55.3       55.6         55.6     Medium   \n",
      "3   ONI_004       59.8      46.9       46.3         46.9      Small   \n",
      "4   ONI_005       41.8      48.2       54.3         54.3     Medium   \n",
      "\n",
      "   black_spots_count  surface_texture_score  skin_condition_score  \\\n",
      "0                  8                      4                     5   \n",
      "1                  4                      2                     4   \n",
      "2                 19                      4                     4   \n",
      "3                  7                      2                     3   \n",
      "4                 12                      4                     4   \n",
      "\n",
      "   has_bruises  has_cuts  has_lesions  visible_damage_flag  \\\n",
      "0            0         1            0                    1   \n",
      "1            1         0            0                    1   \n",
      "2            1         0            1                    1   \n",
      "3            0         0            0                    0   \n",
      "4            0         0            1                    1   \n",
      "\n",
      "   estimated_shelf_life_days quality_grade  \n",
      "0                        1.0             D  \n",
      "1                        1.0             D  \n",
      "2                        1.0             D  \n",
      "3                        7.5             D  \n",
      "4                        1.0             D  \n",
      "\n",
      "Dataset statistics:\n",
      "        length_mm    width_mm   height_mm  diameter_mm  black_spots_count  \\\n",
      "count  200.000000  200.000000  200.000000   200.000000         200.000000   \n",
      "mean    67.634000   74.588000   72.198000    76.525000           5.790000   \n",
      "std     16.280072   18.603548   19.303081    18.932405           5.229977   \n",
      "min     40.000000   35.000000   30.000000    35.000000           0.000000   \n",
      "25%     55.000000   62.475000   60.175000    64.175000           1.000000   \n",
      "50%     67.300000   75.050000   73.100000    77.150000           4.000000   \n",
      "75%     79.325000   87.350000   84.500000    90.825000           9.000000   \n",
      "max    113.000000  124.100000  124.700000   124.700000          21.000000   \n",
      "\n",
      "       surface_texture_score  skin_condition_score  has_bruises    has_cuts  \\\n",
      "count             200.000000            200.000000    200.00000  200.000000   \n",
      "mean                2.570000              3.160000      0.22500    0.145000   \n",
      "std                 1.100525              1.301101      0.41863    0.352984   \n",
      "min                 1.000000              1.000000      0.00000    0.000000   \n",
      "25%                 2.000000              2.000000      0.00000    0.000000   \n",
      "50%                 3.000000              3.000000      0.00000    0.000000   \n",
      "75%                 4.000000              4.000000      0.00000    0.000000   \n",
      "max                 4.000000              5.000000      1.00000    1.000000   \n",
      "\n",
      "       has_lesions  visible_damage_flag  estimated_shelf_life_days  \n",
      "count   200.000000           200.000000                 200.000000  \n",
      "mean      0.205000             0.425000                  11.857500  \n",
      "std       0.404715             0.495584                  10.272853  \n",
      "min       0.000000             0.000000                   1.000000  \n",
      "25%       0.000000             0.000000                   1.000000  \n",
      "50%       0.000000             0.000000                  10.950000  \n",
      "75%       0.000000             1.000000                  20.350000  \n",
      "max       1.000000             1.000000                  34.700000  \n",
      "\n",
      "Categorical variable distributions:\n",
      "\n",
      "Size class distribution:\n",
      "size_class\n",
      "Large          91\n",
      "Medium         70\n",
      "Extra Large    20\n",
      "Small          19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Quality grade distribution:\n",
      "quality_grade\n",
      "D    95\n",
      "C    44\n",
      "A    32\n",
      "B    29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Surface texture distribution:\n",
      "surface_texture_score\n",
      "3    57\n",
      "4    51\n",
      "2    47\n",
      "1    45\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Skin condition distribution:\n",
      "skin_condition_score\n",
      "3    56\n",
      "4    49\n",
      "5    36\n",
      "1    30\n",
      "2    29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Damage indicators:\n",
      "Samples with bruises: 45\n",
      "Samples with cuts: 29\n",
      "Samples with lesions: 41\n",
      "Samples with any visible damage: 85\n",
      "Dataset saved as 'onion_shelf_life_dataset.csv'\n",
      "\n",
      "============================================================\n",
      "DATA DICTIONARY\n",
      "============================================================\n",
      "sample_id: Unique identifier for each onion sample\n",
      "length_mm: Vertical dimension of onion (mm)\n",
      "width_mm: Horizontal diameter of onion (mm)\n",
      "height_mm: Depth dimension of onion (mm)\n",
      "diameter_mm: Maximum diameter for size classification (mm)\n",
      "size_class: Size category (Small/Medium/Large/Extra Large)\n",
      "black_spots_count: Number of visible black spots from image analysis\n",
      "surface_texture_score: Surface condition (1=smooth to 4=very soft)\n",
      "skin_condition_score: Skin/neck condition (1=excellent to 5=poor)\n",
      "has_bruises: Binary flag for visible bruising (0/1)\n",
      "has_cuts: Binary flag for cuts or wounds (0/1)\n",
      "has_lesions: Binary flag for soft spots or lesions (0/1)\n",
      "visible_damage_flag: Binary flag for any visible damage (0/1)\n",
      "estimated_shelf_life_days: Predicted remaining shelf life (days)\n",
      "quality_grade: Overall quality grade (A/B/C/D)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Onion Shelf Life Data Generator\n",
    "==============================\n",
    "\n",
    "This script generates synthetic data for onion shelf life prediction based on \n",
    "visual parameters that can be extracted through image processing and computer vision.\n",
    "\n",
    "Parameters included:\n",
    "- Physical dimensions (length, width, height, diameter)\n",
    "- Visual defects (black spots count)\n",
    "- Surface texture indicators (from image analysis)\n",
    "- Skin/neck condition scoring\n",
    "- Visible damage flags (bruises, cuts, lesions)\n",
    "- Estimated shelf life and quality grading\n",
    "\n",
    "Author: Generated for onion storage optimization project\n",
    "Date: September 2025\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_onion_data(n_samples=200):\n",
    "    \"\"\"\n",
    "    Generate synthetic onion data for shelf life prediction using image-based parameters\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        Number of data points to generate (default: 200)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing synthetic onion data with visual parameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Basic dimensions (in mm)\n",
    "        # Typical onion sizes range from small (50-70mm) to large (80-120mm) diameter\n",
    "        base_size = np.random.normal(75, 15)  # Base size with some variation\n",
    "\n",
    "        # Length (vertical dimension)\n",
    "        length = max(40, np.random.normal(base_size * 0.9, 8))\n",
    "\n",
    "        # Width (horizontal diameter)\n",
    "        width = max(35, np.random.normal(base_size, 10))\n",
    "\n",
    "        # Height (depth, usually similar to width)\n",
    "        height = max(30, np.random.normal(width * 0.95, 8))\n",
    "\n",
    "        # Bulb diameter (primary measurement for size classification)\n",
    "        diameter = max(width, height)\n",
    "\n",
    "        # Size classification based on diameter\n",
    "        if diameter < 50:\n",
    "            size_class = \"Small\"\n",
    "        elif diameter < 75:\n",
    "            size_class = \"Medium\" \n",
    "        elif diameter < 100:\n",
    "            size_class = \"Large\"\n",
    "        else:\n",
    "            size_class = \"Extra Large\"\n",
    "\n",
    "        # Black spots (count visible on surface from image analysis)\n",
    "        # Fresh onions have fewer spots, deteriorating ones have more\n",
    "        freshness_factor = np.random.uniform(0, 1)\n",
    "        if freshness_factor > 0.8:  # Very fresh\n",
    "            black_spots = np.random.poisson(0.5)  # Very few spots\n",
    "        elif freshness_factor > 0.6:  # Moderately fresh\n",
    "            black_spots = np.random.poisson(2)\n",
    "        elif freshness_factor > 0.3:  # Starting to deteriorate  \n",
    "            black_spots = np.random.poisson(5)\n",
    "        else:  # Poor condition\n",
    "            black_spots = np.random.poisson(12)\n",
    "\n",
    "        # Surface texture indicators (from image analysis)\n",
    "        # Smooth = 1 (fresh), Wrinkled = 2, Very wrinkled = 3, Soft appearance = 4\n",
    "        if freshness_factor > 0.7:\n",
    "            surface_texture = np.random.choice([1, 2], p=[0.8, 0.2])\n",
    "        elif freshness_factor > 0.4:\n",
    "            surface_texture = np.random.choice([2, 3], p=[0.6, 0.4])  \n",
    "        else:\n",
    "            surface_texture = np.random.choice([3, 4], p=[0.4, 0.6])\n",
    "\n",
    "        # Skin/neck condition scoring (1-5 scale, 1=excellent, 5=poor)\n",
    "        # Factors: dryness, cracks, open necks, visible rot\n",
    "        if freshness_factor > 0.8:\n",
    "            skin_condition = np.random.choice([1, 2], p=[0.7, 0.3])\n",
    "        elif freshness_factor > 0.6:\n",
    "            skin_condition = np.random.choice([2, 3], p=[0.5, 0.5])\n",
    "        elif freshness_factor > 0.3:\n",
    "            skin_condition = np.random.choice([3, 4], p=[0.6, 0.4])\n",
    "        else:\n",
    "            skin_condition = np.random.choice([4, 5], p=[0.4, 0.6])\n",
    "\n",
    "        # Visible damage flags (binary - detectable from images)\n",
    "        # Bruises\n",
    "        has_bruises = 1 if freshness_factor < 0.5 and np.random.random() < 0.4 else 0\n",
    "\n",
    "        # Cuts/lesions\n",
    "        has_cuts = 1 if np.random.random() < 0.15 else 0  # Random damage during handling\n",
    "\n",
    "        # Visible lesions/soft spots\n",
    "        has_lesions = 1 if freshness_factor < 0.3 and np.random.random() < 0.6 else 0\n",
    "\n",
    "        # Overall damage flag\n",
    "        has_visible_damage = 1 if (has_bruises or has_cuts or has_lesions) else 0\n",
    "\n",
    "        # Estimated shelf life (days) - target variable\n",
    "        # Based on overall condition indicators\n",
    "        base_shelf_life = 30  # Baseline for perfect onion\n",
    "\n",
    "        # Reduce shelf life based on various factors\n",
    "        shelf_life = base_shelf_life\n",
    "        shelf_life -= black_spots * 0.8  # Each spot reduces life\n",
    "        shelf_life -= (surface_texture - 1) * 3  # Texture degradation\n",
    "        shelf_life -= (skin_condition - 1) * 4  # Skin condition impact\n",
    "        shelf_life -= has_visible_damage * 8  # Visible damage penalty\n",
    "\n",
    "        # Add some randomness and ensure positive values\n",
    "        shelf_life += np.random.normal(0, 3)  # Natural variation\n",
    "        shelf_life = max(1, min(45, shelf_life))  # Constrain between 1-45 days\n",
    "\n",
    "        # Quality grade (A, B, C, D)\n",
    "        if shelf_life > 25:\n",
    "            quality_grade = \"A\"\n",
    "        elif shelf_life > 18:\n",
    "            quality_grade = \"B\" \n",
    "        elif shelf_life > 10:\n",
    "            quality_grade = \"C\"\n",
    "        else:\n",
    "            quality_grade = \"D\"\n",
    "\n",
    "        data.append({\n",
    "            'sample_id': f'ONI_{i+1:03d}',\n",
    "            'length_mm': round(length, 1),\n",
    "            'width_mm': round(width, 1), \n",
    "            'height_mm': round(height, 1),\n",
    "            'diameter_mm': round(diameter, 1),\n",
    "            'size_class': size_class,\n",
    "            'black_spots_count': int(black_spots),\n",
    "            'surface_texture_score': int(surface_texture),  # 1=smooth, 4=very soft\n",
    "            'skin_condition_score': int(skin_condition),  # 1=excellent, 5=poor\n",
    "            'has_bruises': has_bruises,\n",
    "            'has_cuts': has_cuts, \n",
    "            'has_lesions': has_lesions,\n",
    "            'visible_damage_flag': has_visible_damage,\n",
    "            'estimated_shelf_life_days': round(shelf_life, 1),\n",
    "            'quality_grade': quality_grade\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def save_dataset(df, filename='onion_shelf_life_dataset.csv'):\n",
    "    \"\"\"Save the generated dataset to CSV file\"\"\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Dataset saved as '{filename}'\")\n",
    "\n",
    "def print_dataset_summary(df):\n",
    "    \"\"\"Print summary statistics and information about the dataset\"\"\"\n",
    "    print(f\"Dataset created with {len(df)} samples\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\nDataset statistics:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    print(\"\\nCategorical variable distributions:\")\n",
    "    print(\"\\nSize class distribution:\")\n",
    "    print(df['size_class'].value_counts())\n",
    "\n",
    "    print(\"\\nQuality grade distribution:\")  \n",
    "    print(df['quality_grade'].value_counts())\n",
    "\n",
    "    print(\"\\nSurface texture distribution:\")\n",
    "    print(df['surface_texture_score'].value_counts())\n",
    "\n",
    "    print(\"\\nSkin condition distribution:\")\n",
    "    print(df['skin_condition_score'].value_counts())\n",
    "\n",
    "    print(\"\\nDamage indicators:\")\n",
    "    print(f\"Samples with bruises: {df['has_bruises'].sum()}\")\n",
    "    print(f\"Samples with cuts: {df['has_cuts'].sum()}\")\n",
    "    print(f\"Samples with lesions: {df['has_lesions'].sum()}\")\n",
    "    print(f\"Samples with any visible damage: {df['visible_damage_flag'].sum()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate the dataset\n",
    "    print(\"Generating 200 onion data points for image-based shelf life prediction...\")\n",
    "    df = generate_onion_data(200)\n",
    "\n",
    "    # Print summary\n",
    "    print_dataset_summary(df)\n",
    "\n",
    "    # Save to CSV\n",
    "    save_dataset(df)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA DICTIONARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"sample_id: Unique identifier for each onion sample\")\n",
    "    print(\"length_mm: Vertical dimension of onion (mm)\")\n",
    "    print(\"width_mm: Horizontal diameter of onion (mm)\")  \n",
    "    print(\"height_mm: Depth dimension of onion (mm)\")\n",
    "    print(\"diameter_mm: Maximum diameter for size classification (mm)\")\n",
    "    print(\"size_class: Size category (Small/Medium/Large/Extra Large)\")\n",
    "    print(\"black_spots_count: Number of visible black spots from image analysis\")\n",
    "    print(\"surface_texture_score: Surface condition (1=smooth to 4=very soft)\")\n",
    "    print(\"skin_condition_score: Skin/neck condition (1=excellent to 5=poor)\")\n",
    "    print(\"has_bruises: Binary flag for visible bruising (0/1)\")\n",
    "    print(\"has_cuts: Binary flag for cuts or wounds (0/1)\")\n",
    "    print(\"has_lesions: Binary flag for soft spots or lesions (0/1)\")  \n",
    "    print(\"visible_damage_flag: Binary flag for any visible damage (0/1)\")\n",
    "    print(\"estimated_shelf_life_days: Predicted remaining shelf life (days)\")\n",
    "    print(\"quality_grade: Overall quality grade (A/B/C/D)\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1ef5c",
   "metadata": {
    "papermill": {
     "duration": 0.0018,
     "end_time": "2026-01-26T17:49:17.959418",
     "exception": false,
     "start_time": "2026-01-26T17:49:17.957618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.395818,
   "end_time": "2026-01-26T17:49:18.583823",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-26T17:49:08.188005",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
